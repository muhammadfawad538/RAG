{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Onsxn_3R0Imf"
      },
      "outputs": [],
      "source": [
        "# Run this cell (may take a minute)\n",
        "!pip install --upgrade pip\n",
        "!pip install reportlab pypdf sentence-transformers faiss-cpu neo4j python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "pdf_path = \"/content/finance_report.pdf\"\n",
        "\n",
        "c = canvas.Canvas(pdf_path, pagesize=letter)\n",
        "text = c.beginText(50, 750)\n",
        "text.setFont(\"Helvetica\", 11)\n",
        "\n",
        "content = \"\"\"\n",
        "FinTech Global â€” Q2 2025 Financial Overview\n",
        "\n",
        "Departments:\n",
        "1. Investment Research â€” led by Sarah Khan\n",
        "   - Projects:\n",
        "     * AI Credit Scoring â€” Budget: $5,000,000\n",
        "     * Portfolio Optimization â€” Budget: $4,000,000\n",
        "   - Employees:\n",
        "     * Ali Raza â€” Data Analyst\n",
        "     * Hina Tariq â€” Junior Analyst\n",
        "\n",
        "2. Risk Management â€” led by Fatima Noor\n",
        "   - Projects:\n",
        "     * Sustainable Investments â€” Budget: $8,000,000\n",
        "   - Employees:\n",
        "     * Bilal Ahmed â€” Compliance Officer\n",
        "     * Ayesha Malik â€” Financial Analyst\n",
        "\n",
        "Company Notes:\n",
        "FinTech Global continues to expand its AI investments and expects higher recurring revenue from services.\n",
        "\"\"\"\n",
        "\n",
        "for line in content.strip().split(\"\\n\"):\n",
        "    text.textLine(line)\n",
        "c.drawText(text)\n",
        "c.save()\n",
        "\n",
        "print(\"âœ… Dummy PDF written to:\", pdf_path)\n"
      ],
      "metadata": {
        "id": "98vTgby50PVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "pdf_path = \"/content/finance_report.pdf\"\n",
        "\n",
        "reader = PdfReader(pdf_path)\n",
        "pages = [p.extract_text() or \"\" for p in reader.pages]\n",
        "full_text = \"\\n\".join(pages)\n",
        "print(\"âœ… Extracted text (preview):\\n\")\n",
        "print(full_text[:1000])\n"
      ],
      "metadata": {
        "id": "5Yxw6zxe0PRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, pprint\n",
        "\n",
        "text = full_text\n",
        "\n",
        "# Simple rule-based extraction tuned to the dummy PDF's structure.\n",
        "# This is intentionally simple; for production use use NER (spaCy) or LLM-based extraction.\n",
        "\n",
        "data = {}\n",
        "current_dept = None\n",
        "\n",
        "lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "for ln in lines:\n",
        "    # Department header like \"1. Investment Research â€” led by Sarah Khan\"\n",
        "    m = re.match(r'^\\d+\\.\\s*(.+?)\\s*â€”\\s*led by\\s*(.+)$', ln, flags=re.I)\n",
        "    if m:\n",
        "        dept_name = m.group(1).strip()\n",
        "        head = m.group(2).strip()\n",
        "        current_dept = dept_name\n",
        "        data[current_dept] = {\"head\": head, \"projects\": [], \"employees\": []}\n",
        "        continue\n",
        "\n",
        "    # Project lines like \"* AI Credit Scoring â€” Budget: $5,000,000\"\n",
        "    m = re.match(r'^[\\*\\-\\â€¢]\\s*(.+?)\\s*â€”\\s*Budget:\\s*\\$?([\\d,]+)', ln)\n",
        "    if m and current_dept:\n",
        "        pname = m.group(1).strip()\n",
        "        budget = int(m.group(2).replace(\",\", \"\"))\n",
        "        data[current_dept][\"projects\"].append({\"name\": pname, \"budget\": budget})\n",
        "        continue\n",
        "\n",
        "    # Employee lines like \"* Ali Raza â€” Data Analyst\"\n",
        "    m = re.match(r'^[\\*\\-\\â€¢]\\s*(.+?)\\s*â€”\\s*(.+)$', ln)\n",
        "    if m and current_dept:\n",
        "        # check it's under employees (we assume later lines)\n",
        "        name = m.group(1).strip()\n",
        "        role = m.group(2).strip()\n",
        "        # heuristics: if role contains 'Analyst' or 'Officer' treat as employee\n",
        "        data[current_dept][\"employees\"].append({\"name\": name, \"role\": role})\n",
        "        continue\n",
        "\n",
        "pprint.pprint(data)\n"
      ],
      "metadata": {
        "id": "jBpuFf_N0PP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "# â† REPLACE these with your AuraDB (or local) credentials\n",
        "NEO4J_URI = \"bolt://localhost:7687\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"password\"\n",
        "\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
        "\n",
        "def run_cypher(cypher, params=None):\n",
        "    with driver.session() as session:\n",
        "        res = session.run(cypher, params or {})\n",
        "        return [r.data() for r in res]\n",
        "\n",
        "# Clear DB (CAUTION: removes all nodes) â€” comment out if you don't want this\n",
        "print(\"Clearing DB (if any) ...\")\n",
        "run_cypher(\"MATCH (n) DETACH DELETE n\")\n",
        "\n",
        "# Create company node\n",
        "COMPANY = \"FinTech Global\"\n",
        "run_cypher(\"MERGE (c:Company {name:$company})\", {\"company\": COMPANY})\n",
        "\n",
        "# Insert departments, heads, employees and projects from extracted data\n",
        "for dept, info in data.items():\n",
        "    # Merge department and link to company\n",
        "    run_cypher(\"\"\"\n",
        "    MERGE (d:Department {name:$dept})\n",
        "    WITH d\n",
        "    MATCH (c:Company {name:$company})\n",
        "    MERGE (c)-[:HAS_DEPARTMENT]->(d)\n",
        "    \"\"\", {\"dept\": dept, \"company\": COMPANY})\n",
        "\n",
        "    # Head\n",
        "    head_name = info.get(\"head\")\n",
        "    if head_name:\n",
        "        run_cypher(\"\"\"\n",
        "        MERGE (h:Employee {name:$head_name})\n",
        "        SET h.title = $title\n",
        "        WITH h\n",
        "        MATCH (d:Department {name:$dept})\n",
        "        MERGE (h)-[:HEADS]->(d)\n",
        "        \"\"\", {\"head_name\": head_name, \"title\": f\"Head of {dept}\", \"dept\": dept})\n",
        "\n",
        "    # Employees\n",
        "    for emp in info.get(\"employees\", []):\n",
        "        run_cypher(\"\"\"\n",
        "        MERGE (e:Employee {name:$ename})\n",
        "        SET e.role = $erole\n",
        "        WITH e\n",
        "        MATCH (d:Department {name:$dept})\n",
        "        MERGE (e)-[:WORKS_IN]->(d)\n",
        "        \"\"\", {\"ename\": emp[\"name\"], \"erole\": emp[\"role\"], \"dept\": dept})\n",
        "\n",
        "    # Projects\n",
        "    for proj in info.get(\"projects\", []):\n",
        "        run_cypher(\"\"\"\n",
        "        MERGE (p:Project {name:$pname})\n",
        "        SET p.budget = $pbudget\n",
        "        WITH p\n",
        "        MATCH (d:Department {name:$dept})\n",
        "        MERGE (d)-[:MANAGES]->(p)\n",
        "        \"\"\", {\"pname\": proj[\"name\"], \"pbudget\": proj[\"budget\"], \"dept\": dept})\n",
        "\n",
        "print(\"âœ… Graph populated in Neo4j.\")\n"
      ],
      "metadata": {
        "id": "0EccN-Z11K6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Who reports to the head of Investment Research? (Employees in that dept)\n",
        "q1 = \"\"\"\n",
        "MATCH (h:Employee {title: 'Head of Investment Research'})-[:HEADS]->(d:Department)<-[:WORKS_IN]-(e:Employee)\n",
        "RETURN e.name AS employee\n",
        "\"\"\"\n",
        "print(\"Who reports to Head of Investment Research?\")\n",
        "print(run_cypher(q1))\n",
        "\n",
        "# Which department manages 'AI Credit Scoring'?\n",
        "q2 = \"\"\"\n",
        "MATCH (d:Department)-[:MANAGES]->(p:Project {name: 'AI Credit Scoring'})\n",
        "RETURN d.name AS department\n",
        "\"\"\"\n",
        "print(\"Which department manages AI Credit Scoring?\")\n",
        "print(run_cypher(q2))\n",
        "\n",
        "# List projects under company\n",
        "q3 = \"\"\"\n",
        "MATCH (c:Company {name: $company})-[:HAS_DEPARTMENT]->(d:Department)-[:MANAGES]->(p:Project)\n",
        "RETURN p.name AS project, p.budget AS budget\n",
        "\"\"\"\n",
        "print(\"Projects under company:\")\n",
        "print(run_cypher(q3, {\"company\": COMPANY}))\n"
      ],
      "metadata": {
        "id": "vrF41BpV1K3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "from math import ceil\n",
        "\n",
        "# 1) Chunk the text (simple fixed-size splitter)\n",
        "def naive_chunks(text, chunk_size=800):\n",
        "    tokens = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), chunk_size):\n",
        "        chunks.append(\" \".join(tokens[i:i+chunk_size]))\n",
        "    return chunks\n",
        "\n",
        "chunks = naive_chunks(full_text, chunk_size=120)  # smaller chunk_size for short doc\n",
        "print(\"Number of text chunks:\", len(chunks))\n",
        "\n",
        "# 2) Embeddings\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embs = model.encode(chunks, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "# 3) Build FAISS index\n",
        "d = embs.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(embs)\n",
        "print(\"FAISS index built. n_items =\", index.ntotal)\n",
        "\n",
        "# Save index and chunks for reuse\n",
        "faiss.write_index(index, \"/content/faiss_index.bin\")\n",
        "with open(\"/content/chunks.pkl\", \"wb\") as f:\n",
        "    pickle.dump(chunks, f)\n",
        "print(\"Saved FAISS index and chunks.\")\n"
      ],
      "metadata": {
        "id": "6OL8VB5h1K1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle, faiss, numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load\n",
        "index = faiss.read_index(\"/content/faiss_index.bin\")\n",
        "with open(\"/content/chunks.pkl\", \"rb\") as f:\n",
        "    chunks = pickle.load(f)\n",
        "smodel = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def retrieve_docs(query, top_k=3):\n",
        "    qvec = smodel.encode([query], convert_to_numpy=True)\n",
        "    D, I = index.search(qvec, top_k)\n",
        "    results = [chunks[idx] for idx in I[0] if idx < len(chunks)]\n",
        "    return results\n",
        "\n",
        "print(\"Example retrieval for 'projects budgets':\")\n",
        "print(retrieve_docs(\"projects and their budgets\", top_k=3))\n"
      ],
      "metadata": {
        "id": "wQxmfd651Kzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”¹ Groq-Based LLM Integration for Finance Graph-RAG\n",
        "!pip install langchain-groq --quiet\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "\n",
        "# Set your Groq API key (replace with your own)\n",
        "os.environ[\"GROQ_API_KEY\"] = \"your_groq_api_key_here\"\n",
        "\n",
        "\n",
        "# Initialize Groq LLM\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "def llm_answer_groq(context, question):\n",
        "    \"\"\"\n",
        "    Uses Groq's LLM (LLaMA-3.1-8B-Instant) to answer questions based on retrieved finance docs.\n",
        "    \"\"\"\n",
        "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer clearly and concisely.\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content\n",
        "\n",
        "# Example usage\n",
        "docs = retrieve_docs(\"What are the budgets for the projects?\", top_k=3)\n",
        "context = \"\\n\\n\".join(docs)\n",
        "print(llm_answer_groq(context, \"List the projects and their budgets.\"))\n"
      ],
      "metadata": {
        "id": "we9TEv9e364-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_nl(question):\n",
        "    ql = question.lower()\n",
        "    # very simple heuristic routing\n",
        "    graph_keywords = [\"who reports\", \"who report\", \"which department\", \"manages\", \"which projects\", \"budget\", \"head of\"]\n",
        "    if any(k in ql for k in [\"who reports\", \"who report\", \"head of\", \"works in\", \"reports to\", \"which department\", \"manages\"]):\n",
        "        # map some patterns to prepared cypher queries\n",
        "        if \"who reports to\" in ql or \"who reports\" in ql:\n",
        "            # find head title or name extraction\n",
        "            if \"head of\" in ql:\n",
        "                # e.g., \"Who reports to the Head of Investment Research?\"\n",
        "                # extract department name after \"head of\"\n",
        "                part = ql.split(\"head of\")[-1].strip().strip(\"? \").title()\n",
        "                cy = \"\"\"\n",
        "                MATCH (h:Employee {title:$title})-[:HEADS]->(d:Department)<-[:WORKS_IN]-(e:Employee)\n",
        "                RETURN e.name AS employee\n",
        "                \"\"\"\n",
        "                title = f\"Head Of {part}\" if not ql.count(\"head of\") else f\"Head of {part}\"\n",
        "                # Because our graph saved title as 'Head of Investment Research', ensure match casing\n",
        "                rows = run_cypher(cy, {\"title\": f\"Head of {part}\"})\n",
        "                names = [r[\"employee\"] for r in rows]\n",
        "                return \", \".join(names) if names else \"No matching employees found.\"\n",
        "\n",
        "        if \"which department\" in ql and \"manages\" in ql:\n",
        "            # find project name in the question (naive)\n",
        "            m = re.search(r'project\\s+(.+?)(\\?|$)', ql)\n",
        "            if m:\n",
        "                pname = m.group(1).strip().title()\n",
        "                cy = \"\"\"\n",
        "                MATCH (d:Department)-[:MANAGES]->(p:Project {name:$pname})\n",
        "                RETURN d.name AS department\n",
        "                \"\"\"\n",
        "                rows = run_cypher(cy, {\"pname\": pname})\n",
        "                return \", \".join([r[\"department\"] for r in rows]) if rows else \"No department found.\"\n",
        "\n",
        "        # fallback: run a general search in graph trying to find named entities\n",
        "        # list all employees and department names and check if any are in the question\n",
        "        all_nodes = run_cypher(\"MATCH (n) RETURN labels(n) as labels, n.name as name\")\n",
        "        names = [r[\"name\"] for r in all_nodes if r.get(\"name\")]\n",
        "        found = [n for n in names if n.lower() in ql]\n",
        "        if found:\n",
        "            # return node summary for first match\n",
        "            nm = found[0]\n",
        "            cy = \"MATCH (n {name:$name})-[r]-(m) RETURN type(r) as rel, m.name as other\"\n",
        "            rows = run_cypher(cy, {\"name\": nm})\n",
        "            return f\"Relations for {nm}: \" + \", \".join([f\"{r['rel']} -> {r['other']}\" for r in rows]) if rows else \"No relations found.\"\n",
        "\n",
        "        return \"Couldn't map question to graph. Try a different phrasing.\"\n",
        "\n",
        "    else:\n",
        "        # document route: retrieve top-3 chunks and call LLM (OpenAI example)\n",
        "        docs = retrieve_docs(question, top_k=3)\n",
        "        context = \"\\n\\n\".join(docs)\n",
        "        # if you set OpenAI key above, use llm_answer_openai; otherwise return the context\n",
        "        try:\n",
        "            ans = llm_answer_openai(context, question)\n",
        "            return ans\n",
        "        except Exception as e:\n",
        "            return f\"No LLM key found or LLM error. Returning context:\\n\\n{context[:1000]}\"\n",
        "\n",
        "# Try combined QA:\n",
        "examples = [\n",
        "    \"Who reports to the Head of Investment Research?\",\n",
        "    \"Which department manages AI Credit Scoring project?\",\n",
        "    \"What are the budgets of the projects?\",\n",
        "    \"What recommendations does the report give?\"\n",
        "]\n",
        "\n",
        "for q in examples:\n",
        "    print(\"\\nQ:\", q)\n",
        "    print(\"A:\", answer_nl(q))\n"
      ],
      "metadata": {
        "id": "lOVc4wsj3qpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_h_Btih8F_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0j3CyqWx8F92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}